{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methylation-Based Cancer Detection Classifier\n",
    "## A GRAIL/Galleri-inspired approach using TCGA data\n",
    "\n",
    "This notebook walks through building a simplified version of a multi-cancer early detection\n",
    "classifier from methylation data — the same core concept behind GRAIL's Galleri test.\n",
    "\n",
    "**What we're building:**\n",
    "1. A cancer detection classifier (cancer vs normal) from methylation features\n",
    "2. A tissue-of-origin classifier (which cancer type) from the same features\n",
    "3. A synthetic dilution experiment simulating real ctDNA tumor fractions\n",
    "\n",
    "**Data source:** TCGA Illumina 450K methylation arrays via the GDC Data Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install pandas numpy scikit-learn matplotlib seaborn xgboost requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost available\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import os\n",
    "import gzip\n",
    "import io\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score, precision_recall_curve,\n",
    "    confusion_matrix, classification_report, auc\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing xgboost (optional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "    print(\"XGBoost available\")\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print(\"XGBoost not installed -- will skip XGBoost comparisons\")\n",
    "\n",
    "# Plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create data directory\n",
    "DATA_DIR = Path('data/tcga_methylation')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Download TCGA Methylation Data via GDC API\n",
    "\n",
    "We'll pull Illumina 450K methylation beta values from the GDC for 3 cancer types\n",
    "that are high priority for ctDNA-based diagnostics:\n",
    "\n",
    "- **TCGA-LUAD** — Lung adenocarcinoma\n",
    "- **TCGA-COAD** — Colon adenocarcinoma  \n",
    "- **TCGA-PAAD** — Pancreatic adenocarcinoma\n",
    "\n",
    "For each project, we'll download both tumor and solid tissue normal samples.\n",
    "\n",
    "### How GDC data works\n",
    "Each sample produces a single file with ~485K CpG probe IDs and their beta values.\n",
    "We query the GDC API for file UUIDs, download each file, and merge into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# GDC API helper functions\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "GDC_FILES_ENDPOINT = \"https://api.gdc.cancer.gov/files\"\n",
    "GDC_DATA_ENDPOINT = \"https://api.gdc.cancer.gov/data\"\n",
    "\n",
    "\n",
    "def query_gdc_methylation_files(project_id, sample_type=\"Primary Tumor\", max_files=30):\n",
    "    \"\"\"\n",
    "    Query GDC API for 450K methylation beta-value files.\n",
    "    \n",
    "    sample_type: 'Primary Tumor' or 'Solid Tissue Normal'\n",
    "    \"\"\"\n",
    "    filters = {\n",
    "        \"op\": \"and\",\n",
    "        \"content\": [\n",
    "            {\"op\": \"=\", \"content\": {\"field\": \"cases.project.project_id\", \"value\": project_id}},\n",
    "            {\"op\": \"=\", \"content\": {\"field\": \"data_category\", \"value\": \"DNA Methylation\"}},\n",
    "            {\"op\": \"=\", \"content\": {\"field\": \"data_type\", \"value\": \"Methylation Beta Value\"}},\n",
    "            {\"op\": \"=\", \"content\": {\"field\": \"platform\", \"value\": \"Illumina Human Methylation 450\"}},\n",
    "            {\"op\": \"=\", \"content\": {\"field\": \"cases.samples.sample_type\", \"value\": sample_type}},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"filters\": str(filters).replace(\"'\", '\"'),\n",
    "        \"fields\": \"file_id,file_name,cases.case_id,cases.project.project_id,cases.samples.sample_type\",\n",
    "        \"format\": \"JSON\",\n",
    "        \"size\": str(max_files)\n",
    "    }\n",
    "\n",
    "    response = requests.get(GDC_FILES_ENDPOINT, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    files = []\n",
    "    for hit in data.get(\"data\", {}).get(\"hits\", []):\n",
    "        files.append({\n",
    "            \"file_id\": hit[\"file_id\"],\n",
    "            \"file_name\": hit[\"file_name\"],\n",
    "            \"project\": project_id,\n",
    "            \"sample_type\": sample_type\n",
    "        })\n",
    "    \n",
    "    print(f\"  Found {len(files)} {sample_type} files for {project_id}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "def download_methylation_file(file_id, cache_dir=DATA_DIR):\n",
    "    \"\"\"\n",
    "    Download a single methylation beta-value file from GDC.\n",
    "    Returns a pandas Series of beta values indexed by CpG probe ID.\n",
    "    \"\"\"\n",
    "    cache_path = cache_dir / f\"{file_id}.pkl\"\n",
    "    \n",
    "    # Use cached version if available\n",
    "    if cache_path.exists():\n",
    "        return pd.read_pickle(cache_path)\n",
    "    \n",
    "    url = f\"{GDC_DATA_ENDPOINT}/{file_id}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # GDC returns tab-separated files, possibly gzipped\n",
    "    try:\n",
    "        content = gzip.decompress(response.content).decode('utf-8')\n",
    "    except gzip.BadGzipFile:\n",
    "        content = response.content.decode('utf-8')\n",
    "    \n",
    "    df = pd.read_csv(io.StringIO(content), sep='\\t', comment='#')\n",
    "    \n",
    "    # GDC 450K files typically have columns:\n",
    "    # 'Composite Element REF' (probe ID) and 'Beta_value'\n",
    "    probe_col = [c for c in df.columns if 'composite' in c.lower() or 'probe' in c.lower()]\n",
    "    beta_col = [c for c in df.columns if 'beta' in c.lower()]\n",
    "    \n",
    "    if probe_col and beta_col:\n",
    "        series = df.set_index(probe_col[0])[beta_col[0]]\n",
    "    else:\n",
    "        # Fallback: assume first col is probe ID, second is beta\n",
    "        series = df.set_index(df.columns[0])[df.columns[1]]\n",
    "    \n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    series.name = file_id\n",
    "    \n",
    "    # Cache to disk\n",
    "    series.to_pickle(cache_path)\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying GDC for methylation files...\n",
      "\n",
      "  Found 100 Primary Tumor files for TCGA-LUAD\n",
      "  Found 32 Solid Tissue Normal files for TCGA-LUAD\n",
      "  Found 100 Primary Tumor files for TCGA-COAD\n",
      "  Found 38 Solid Tissue Normal files for TCGA-COAD\n",
      "  Found 100 Primary Tumor files for TCGA-PAAD\n",
      "  Found 10 Solid Tissue Normal files for TCGA-PAAD\n",
      "\n",
      "Total files to download: 380\n",
      "project    sample_type        \n",
      "TCGA-COAD  Primary Tumor          100\n",
      "           Solid Tissue Normal     38\n",
      "TCGA-LUAD  Primary Tumor          100\n",
      "           Solid Tissue Normal     32\n",
      "TCGA-PAAD  Primary Tumor          100\n",
      "           Solid Tissue Normal     10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Query files for each cancer type\n",
    "# ------------------------------------------------------------------\n",
    "# Caps are ceilings — GDC returns however many samples exist.\n",
    "# Approximate availability in TCGA:\n",
    "#   LUAD: ~450 tumor, ~59 solid tissue normal\n",
    "#   COAD: ~300 tumor, ~38 solid tissue normal\n",
    "#   PAAD: ~180 tumor, ~10 solid tissue normal\n",
    "# With these settings we expect ~300 tumors and ~107 normals (~407 total).\n",
    "# That gives ~32 normal test samples → reliable specificity estimates to ~97%.\n",
    "\n",
    "PROJECTS = [\"TCGA-LUAD\", \"TCGA-COAD\", \"TCGA-PAAD\"]\n",
    "TUMOR_SAMPLES_PER_PROJECT = 100\n",
    "NORMAL_SAMPLES_PER_PROJECT = 60  # normals are scarcer, especially for PAAD\n",
    "\n",
    "all_files = []\n",
    "\n",
    "print(\"Querying GDC for methylation files...\\n\")\n",
    "for project in PROJECTS:\n",
    "    tumor_files = query_gdc_methylation_files(\n",
    "        project, sample_type=\"Primary Tumor\", max_files=TUMOR_SAMPLES_PER_PROJECT\n",
    "    )\n",
    "    normal_files = query_gdc_methylation_files(\n",
    "        project, sample_type=\"Solid Tissue Normal\", max_files=NORMAL_SAMPLES_PER_PROJECT\n",
    "    )\n",
    "    all_files.extend(tumor_files)\n",
    "    all_files.extend(normal_files)\n",
    "\n",
    "file_manifest = pd.DataFrame(all_files)\n",
    "print(f\"\\nTotal files to download: {len(file_manifest)}\")\n",
    "print(file_manifest.groupby(['project', 'sample_type']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading methylation files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [12:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged beta matrix to cache.\n",
      "\n",
      "Raw beta matrix shape: (486426, 380)\n",
      "  486426 CpG probes x 380 samples\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Download and merge into a beta-value matrix\n",
    "# ------------------------------------------------------------------\n",
    "# Individual sample files are cached by download_methylation_file.\n",
    "# We also cache the merged matrix — assembling 400+ Series into a\n",
    "# single DataFrame is slow even when all files are already on disk.\n",
    "\n",
    "N_SAMPLES = len(file_manifest)\n",
    "BETA_MATRIX_CACHE = DATA_DIR / f\"beta_matrix_{N_SAMPLES}samples.pkl\"\n",
    "\n",
    "if BETA_MATRIX_CACHE.exists():\n",
    "    beta_matrix = pd.read_pickle(BETA_MATRIX_CACHE)\n",
    "    print(f\"Loaded cached beta matrix ({N_SAMPLES} samples)\")\n",
    "else:\n",
    "    beta_series = {}\n",
    "    failed = []\n",
    "\n",
    "    print(\"Downloading methylation files...\")\n",
    "    for _, row in tqdm(file_manifest.iterrows(), total=len(file_manifest)):\n",
    "        try:\n",
    "            series = download_methylation_file(row['file_id'])\n",
    "            beta_series[row['file_id']] = series\n",
    "        except Exception as e:\n",
    "            failed.append(row['file_id'])\n",
    "            print(f\"  Failed: {row['file_id']} — {e}\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"\\n{len(failed)} files failed to download.\")\n",
    "\n",
    "    beta_matrix = pd.DataFrame(beta_series)\n",
    "    beta_matrix.to_pickle(BETA_MATRIX_CACHE)\n",
    "    print(f\"Saved merged beta matrix to cache.\")\n",
    "\n",
    "print(f\"\\nRaw beta matrix shape: {beta_matrix.shape}\")\n",
    "print(f\"  {beta_matrix.shape[0]} CpG probes x {beta_matrix.shape[1]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts:\n",
      "cancer_type  sample_type        \n",
      "COAD         Primary Tumor          100\n",
      "LUAD         Primary Tumor          100\n",
      "Normal       Solid Tissue Normal     80\n",
      "PAAD         Primary Tumor          100\n",
      "dtype: int64\n",
      "\n",
      "Total samples: 380\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Build metadata table linking file IDs to labels\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Create a mapping from file_id to labels\n",
    "metadata = file_manifest.set_index('file_id')[['project', 'sample_type']].copy()\n",
    "\n",
    "# Keep only samples we successfully downloaded\n",
    "metadata = metadata.loc[metadata.index.isin(beta_matrix.columns)]\n",
    "\n",
    "# Create binary cancer label\n",
    "metadata['is_cancer'] = (metadata['sample_type'] == 'Primary Tumor').astype(int)\n",
    "\n",
    "# Create tissue label (cancer type) — only meaningful for tumor samples\n",
    "metadata['cancer_type'] = metadata['project'].str.replace('TCGA-', '')\n",
    "metadata.loc[metadata['is_cancer'] == 0, 'cancer_type'] = 'Normal'\n",
    "\n",
    "print(\"Sample counts:\")\n",
    "print(metadata.groupby(['cancer_type', 'sample_type']).size())\n",
    "print(f\"\\nTotal samples: {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Preprocessing\n",
    "\n",
    "Key filtering steps:\n",
    "- Remove probes with too many missing values\n",
    "- Remove probes on sex chromosomes (avoid sex-based confounding)\n",
    "- Remove probes with known SNPs at the CpG site (the exact problem we discussed)\n",
    "- Impute remaining NAs with the probe median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape: (380, 486426)\n",
      "After missing filter: (380, 410462)\n",
      "NOTE: Sex chromosome filtering skipped — see TODO below\n",
      "Saved feature matrix to cache.\n",
      "\n",
      "Beta value range: [0.004, 0.996]\n",
      "Final feature matrix: 380 samples x 410462 CpG probes\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Preprocessing\n",
    "# ------------------------------------------------------------------\n",
    "# Transpose so rows = samples, columns = CpG probes\n",
    "# This is the standard ML orientation: samples x features\n",
    "\n",
    "XRAW_CACHE = DATA_DIR / f\"X_raw_{N_SAMPLES}samples_missing20.pkl\"\n",
    "\n",
    "if XRAW_CACHE.exists():\n",
    "    X_raw = pd.read_pickle(XRAW_CACHE)\n",
    "    print(f\"Loaded cached feature matrix ({N_SAMPLES} samples)\")\n",
    "else:\n",
    "    X_raw = beta_matrix.T\n",
    "    print(f\"Starting shape: {X_raw.shape}\")\n",
    "\n",
    "    # 1. Remove probes with >20% missing values\n",
    "    missing_frac = X_raw.isnull().mean(axis=0)\n",
    "    good_probes = missing_frac[missing_frac < 0.2].index\n",
    "    X_raw = X_raw[good_probes]\n",
    "    print(f\"After missing filter: {X_raw.shape}\")\n",
    "\n",
    "    # 2. Remove sex chromosome probes\n",
    "    # 450K probe IDs starting with 'cg' are autosomal/X/Y\n",
    "    # We'll filter by known X/Y probe lists if available,\n",
    "    # otherwise skip this step and note it as a TODO\n",
    "    # For now, we keep all probes — in a real analysis you'd\n",
    "    # cross-reference with the 450K manifest annotation file\n",
    "    # to remove chrX and chrY probes.\n",
    "    print(\"NOTE: Sex chromosome filtering skipped — see TODO below\")\n",
    "\n",
    "    # 3. Impute remaining NAs with column (probe) median\n",
    "    X_raw = X_raw.fillna(X_raw.median(axis=0))\n",
    "\n",
    "    X_raw.to_pickle(XRAW_CACHE)\n",
    "    print(f\"Saved feature matrix to cache.\")\n",
    "\n",
    "# 4. Basic sanity check — values should be between 0 and 1\n",
    "print(f\"\\nBeta value range: [{X_raw.min().min():.3f}, {X_raw.max().max():.3f}]\")\n",
    "print(f\"Final feature matrix: {X_raw.shape[0]} samples x {X_raw.shape[1]} CpG probes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# TODO: Enhanced preprocessing for a more rigorous analysis\n",
    "# ------------------------------------------------------------------\n",
    "#\n",
    "# 1. Download the Illumina 450K manifest from:\n",
    "#    https://webdata.illumina.com/downloads/productfiles/humanmethylation450/\n",
    "#    This gives you probe annotations including chromosome, gene, relation\n",
    "#    to CpG island, and known SNP overlap.\n",
    "#\n",
    "# 2. Remove probes on chrX and chrY\n",
    "# 3. Remove probes flagged with SNPs at the CpG site\n",
    "# 4. Remove cross-reactive probes (Chen et al. 2013 published a list)\n",
    "#\n",
    "# For this starter notebook we skip these for simplicity, but they\n",
    "# matter for a real analysis and are good talking points in an interview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Selection\n",
    "\n",
    "With ~450K features and ~100 samples, we need to reduce dimensionality.\n",
    "This mirrors GRAIL's panel design step — going from millions of CpGs\n",
    "down to the most informative subset.\n",
    "\n",
    "We'll use two approaches:\n",
    "1. **Univariate filtering** — rank probes by how well they individually distinguish cancer from normal\n",
    "2. **L1 regularization** — let the model itself select features during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Align features and labels\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Make sure our X matrix and metadata are aligned\n",
    "common_samples = X_raw.index.intersection(metadata.index)\n",
    "X = X_raw.loc[common_samples]\n",
    "y_cancer = metadata.loc[common_samples, 'is_cancer']\n",
    "y_type = metadata.loc[common_samples, 'cancer_type']\n",
    "\n",
    "print(f\"Aligned dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"\\nCancer labels: {y_cancer.value_counts().to_dict()}\")\n",
    "print(f\"Type labels: {y_type.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Train/test split\n",
    "# ------------------------------------------------------------------\n",
    "# Stratify by cancer type to ensure balanced representation\n",
    "\n",
    "X_train, X_test, y_train_cancer, y_test_cancer, y_train_type, y_test_type = \\\n",
    "    train_test_split(\n",
    "        X, y_cancer, y_type,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y_type\n",
    "    )\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Test:  {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTrain cancer type distribution:\")\n",
    "print(y_train_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Univariate feature selection (ANOVA F-test)\n",
    "# ------------------------------------------------------------------\n",
    "# Select top K most differentially methylated probes between\n",
    "# cancer and normal. This is a simple proxy for the DMR analysis\n",
    "# that GRAIL would do with much more sophisticated methods.\n",
    "\n",
    "K_FEATURES = 5000  # start with top 5000 probes\n",
    "\n",
    "SELECTOR_CACHE = DATA_DIR / f\"feature_selection_{N_SAMPLES}samples_k{K_FEATURES}.pkl\"\n",
    "\n",
    "if SELECTOR_CACHE.exists():\n",
    "    selected_probes, f_scores = pd.read_pickle(SELECTOR_CACHE)\n",
    "    X_train_sel = X_train[selected_probes]\n",
    "    X_test_sel = X_test[selected_probes]\n",
    "    print(f\"Loaded cached feature selection ({len(selected_probes)} probes)\")\n",
    "else:\n",
    "    selector = SelectKBest(f_classif, k=K_FEATURES)\n",
    "    selector.fit(X_train, y_train_cancer)\n",
    "\n",
    "    selected_mask = selector.get_support()\n",
    "    selected_probes = X_train.columns[selected_mask]\n",
    "\n",
    "    X_train_sel = X_train[selected_probes]\n",
    "    X_test_sel = X_test[selected_probes]\n",
    "\n",
    "    f_scores = pd.Series(selector.scores_, index=X_train.columns)\n",
    "\n",
    "    pd.to_pickle((selected_probes, f_scores), SELECTOR_CACHE)\n",
    "    print(f\"Saved feature selection to cache.\")\n",
    "\n",
    "top_probes = f_scores.nlargest(20)\n",
    "print(f\"Selected {len(selected_probes)} probes from {X_train.shape[1]}\")\n",
    "print(f\"\\nTop 20 probes by F-score:\")\n",
    "print(top_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Visualize top differentially methylated probes\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for idx, probe in enumerate(top_probes.index[:6]):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    for cancer_type in y_train_type.unique():\n",
    "        mask = y_train_type == cancer_type\n",
    "        ax.hist(\n",
    "            X_train_sel.loc[mask, probe].dropna(),\n",
    "            bins=20, alpha=0.5, label=cancer_type, density=True\n",
    "        )\n",
    "    \n",
    "    ax.set_title(probe, fontsize=10)\n",
    "    ax.set_xlabel('Beta value')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Top Differentially Methylated Probes: Beta Value Distributions by Type', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cancer Detection Classifier\n",
    "\n",
    "Binary classification: cancer vs normal.\n",
    "\n",
    "We'll train:\n",
    "1. L1-regularized logistic regression (most likely what GRAIL uses)\n",
    "2. XGBoost for comparison\n",
    "\n",
    "Key evaluation: **sensitivity at 99.5% specificity** — this is the operating\n",
    "point GRAIL uses for Galleri, and it's the clinically relevant metric for\n",
    "a screening test where false positives are costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Logistic Regression with L1 penalty (LASSO)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "LR_CACHE = DATA_DIR / f\"lr_pipeline_{N_SAMPLES}samples_k{K_FEATURES}.joblib\"\n",
    "\n",
    "if LR_CACHE.exists():\n",
    "    lr_pipeline = joblib.load(LR_CACHE)\n",
    "    print(f\"Loaded cached LR pipeline\")\n",
    "else:\n",
    "    lr_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegressionCV(\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            Cs=20,               # test 20 regularization strengths\n",
    "            cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "            scoring='roc_auc',\n",
    "            max_iter=10000,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"Training L1 Logistic Regression...\")\n",
    "    lr_pipeline.fit(X_train_sel, y_train_cancer)\n",
    "    joblib.dump(lr_pipeline, LR_CACHE)\n",
    "    print(f\"Saved LR pipeline to cache.\")\n",
    "\n",
    "# Check how many features the L1 penalty kept\n",
    "lr_model = lr_pipeline.named_steps['clf']\n",
    "n_nonzero = np.sum(lr_model.coef_[0] != 0)\n",
    "print(f\"  Non-zero features: {n_nonzero} / {len(selected_probes)}\")\n",
    "print(f\"  Best C (regularization): {lr_model.C_[0]:.4f}\")\n",
    "\n",
    "# Predict probabilities on test set\n",
    "lr_probs = lr_pipeline.predict_proba(X_test_sel)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# XGBoost classifier (for comparison)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "if HAS_XGB:\n",
    "    XGB_CACHE = DATA_DIR / f\"xgb_pipeline_{N_SAMPLES}samples_k{K_FEATURES}.joblib\"\n",
    "\n",
    "    if XGB_CACHE.exists():\n",
    "        xgb_pipeline = joblib.load(XGB_CACHE)\n",
    "        print(f\"Loaded cached XGB pipeline\")\n",
    "    else:\n",
    "        xgb_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # not strictly needed for XGB, but keeps things consistent\n",
    "            ('clf', XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                eval_metric='logloss',\n",
    "                random_state=42,\n",
    "                use_label_encoder=False\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        print(\"Training XGBoost...\")\n",
    "        xgb_pipeline.fit(X_train_sel, y_train_cancer)\n",
    "        joblib.dump(xgb_pipeline, XGB_CACHE)\n",
    "        print(f\"Saved XGB pipeline to cache.\")\n",
    "\n",
    "    xgb_probs = xgb_pipeline.predict_proba(X_test_sel)[:, 1]\n",
    "else:\n",
    "    print(\"Skipping XGBoost (not installed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Evaluation: ROC curves and sensitivity at target specificity\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def sensitivity_at_specificity(y_true, y_score, target_spec=0.995):\n",
    "    \"\"\"\n",
    "    Find sensitivity (recall) at a given specificity threshold.\n",
    "    This is the key clinical metric — what fraction of cancers\n",
    "    do we detect while keeping false positive rate at 0.5%?\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    # Specificity = 1 - FPR\n",
    "    specificities = 1 - fpr\n",
    "    # Find the threshold closest to target specificity\n",
    "    idx = np.argmin(np.abs(specificities - target_spec))\n",
    "    return tpr[idx], specificities[idx], thresholds[idx]\n",
    "\n",
    "\n",
    "# ROC curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Full ROC\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_cancer, lr_probs)\n",
    "auc_lr = roc_auc_score(y_test_cancer, lr_probs)\n",
    "ax1.plot(fpr_lr, tpr_lr, label=f'L1 LogReg (AUC={auc_lr:.3f})', linewidth=2)\n",
    "\n",
    "if HAS_XGB:\n",
    "    fpr_xgb, tpr_xgb, _ = roc_curve(y_test_cancer, xgb_probs)\n",
    "    auc_xgb = roc_auc_score(y_test_cancer, xgb_probs)\n",
    "    ax1.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={auc_xgb:.3f})', linewidth=2)\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "ax1.set_title('ROC Curve — Cancer Detection')\n",
    "ax1.legend()\n",
    "\n",
    "# Zoomed ROC at high specificity (the clinically relevant region)\n",
    "ax2.plot(fpr_lr, tpr_lr, label=f'L1 LogReg', linewidth=2)\n",
    "if HAS_XGB:\n",
    "    ax2.plot(fpr_xgb, tpr_xgb, label=f'XGBoost', linewidth=2)\n",
    "\n",
    "ax2.set_xlim([0, 0.05])  # zoom to FPR < 5%\n",
    "ax2.axvline(x=0.005, color='red', linestyle='--', alpha=0.5, label='99.5% specificity')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "ax2.set_title('ROC Curve — Zoomed to High Specificity')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print sensitivity at target specificities\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SENSITIVITY AT TARGET SPECIFICITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for target_spec in [0.99, 0.995, 0.999]:\n",
    "    sens_lr, spec_lr, _ = sensitivity_at_specificity(y_test_cancer, lr_probs, target_spec)\n",
    "    print(f\"\\nAt {target_spec*100:.1f}% specificity:\")\n",
    "    print(f\"  L1 LogReg:  sensitivity = {sens_lr:.3f}\")\n",
    "    if HAS_XGB:\n",
    "        sens_xgb, spec_xgb, _ = sensitivity_at_specificity(y_test_cancer, xgb_probs, target_spec)\n",
    "        print(f\"  XGBoost:    sensitivity = {sens_xgb:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Inspect model features\n",
    "# ------------------------------------------------------------------\n",
    "# One of the advantages of L1 logistic regression: interpretability.\n",
    "# We can see exactly which CpG probes the model relies on.\n",
    "\n",
    "coefs = pd.Series(\n",
    "    lr_model.coef_[0],\n",
    "    index=selected_probes\n",
    ")\n",
    "\n",
    "# Top positive weights (higher methylation → more likely cancer)\n",
    "top_positive = coefs.nlargest(15)\n",
    "# Top negative weights (higher methylation → less likely cancer)\n",
    "top_negative = coefs.nsmallest(15)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "top_positive.plot(kind='barh', ax=ax1, color='firebrick')\n",
    "ax1.set_title('Top Positive Weights\\n(methylation → cancer)')\n",
    "ax1.set_xlabel('Coefficient')\n",
    "\n",
    "top_negative.plot(kind='barh', ax=ax2, color='steelblue')\n",
    "ax2.set_title('Top Negative Weights\\n(methylation → normal)')\n",
    "ax2.set_xlabel('Coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal non-zero coefficients: {(coefs != 0).sum()}\")\n",
    "print(f\"This is analogous to GRAIL's targeted panel — the model is 'using'\")\n",
    "print(f\"only {(coefs != 0).sum()} out of {len(coefs)} probes for its prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Tissue-of-Origin Classifier\n",
    "\n",
    "Multi-class classification on cancer samples only: LUAD vs COAD vs PAAD.\n",
    "\n",
    "This is the second stage of the GRAIL pipeline — once you've detected a\n",
    "cancer signal, predict where it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Tissue-of-Origin classifier\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Filter to cancer samples only\n",
    "cancer_mask_train = y_train_cancer == 1\n",
    "cancer_mask_test = y_test_cancer == 1\n",
    "\n",
    "X_train_cancer = X_train_sel[cancer_mask_train]\n",
    "X_test_cancer = X_test_sel[cancer_mask_test]\n",
    "y_train_tof = y_train_type[cancer_mask_train]\n",
    "y_test_tof = y_test_type[cancer_mask_test]\n",
    "\n",
    "# Remove 'Normal' from labels (shouldn't be any, but just in case)\n",
    "assert (y_train_tof == 'Normal').sum() == 0\n",
    "\n",
    "print(f\"Tissue-of-origin training samples: {len(X_train_cancer)}\")\n",
    "print(y_train_tof.value_counts())\n",
    "\n",
    "TOF_CACHE = DATA_DIR / f\"tof_pipeline_{N_SAMPLES}samples_k{K_FEATURES}.joblib\"\n",
    "\n",
    "if TOF_CACHE.exists():\n",
    "    tof_pipeline = joblib.load(TOF_CACHE)\n",
    "    print(f\"\\nLoaded cached ToF pipeline\")\n",
    "else:\n",
    "    tof_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegressionCV(\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            multi_class='multinomial',\n",
    "            Cs=20,\n",
    "            cv=StratifiedKFold(3, shuffle=True, random_state=42),  # fewer folds due to small sample size\n",
    "            max_iter=10000,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"\\nTraining tissue-of-origin classifier...\")\n",
    "    tof_pipeline.fit(X_train_cancer, y_train_tof)\n",
    "    joblib.dump(tof_pipeline, TOF_CACHE)\n",
    "    print(f\"Saved ToF pipeline to cache.\")\n",
    "\n",
    "tof_preds = tof_pipeline.predict(X_test_cancer)\n",
    "tof_accuracy = (tof_preds == y_test_tof).mean()\n",
    "\n",
    "print(f\"\\nTissue-of-origin accuracy: {tof_accuracy:.1%}\")\n",
    "print(f\"(GRAIL reports 93.4% — with 3 cancer types and array data we should do well)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Confusion matrix for tissue-of-origin\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "labels = sorted(y_test_tof.unique())\n",
    "cm = confusion_matrix(y_test_tof, tof_preds, labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=labels, yticklabels=labels, ax=ax\n",
    ")\n",
    "ax.set_xlabel('Predicted Cancer Type')\n",
    "ax.set_ylabel('True Cancer Type')\n",
    "ax.set_title('Tissue-of-Origin Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_tof, tof_preds, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Synthetic Dilution Experiment\n",
    "\n",
    "This is where we simulate the real ctDNA problem.\n",
    "\n",
    "In a real blood sample, tumor-derived cfDNA is a tiny fraction of the total.\n",
    "We simulate this by blending tumor methylation profiles with normal profiles\n",
    "at known ratios (tumor fractions).\n",
    "\n",
    "For each tumor fraction, we ask: can our classifier still detect the cancer signal?\n",
    "\n",
    "**This directly models the concept of limit of detection (LOD).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Synthetic plasma mixtures\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def create_synthetic_plasma(tumor_profile, normal_profile, tumor_fraction):\n",
    "    \"\"\"\n",
    "    Simulate a plasma cfDNA methylation profile by mixing tumor and\n",
    "    normal profiles at a given tumor fraction.\n",
    "    \n",
    "    At the array level, this is equivalent to a weighted average of\n",
    "    beta values. In real sequencing data, you'd instead be mixing\n",
    "    reads, but the beta-value average is a reasonable approximation\n",
    "    for array data.\n",
    "    \n",
    "    synthetic_beta = (tumor_fraction * tumor_beta) + ((1 - tumor_fraction) * normal_beta)\n",
    "    \"\"\"\n",
    "    return tumor_fraction * tumor_profile + (1 - tumor_fraction) * normal_profile\n",
    "\n",
    "\n",
    "# Get our test set tumor and normal samples\n",
    "test_tumors = X_test_sel[y_test_cancer == 1]\n",
    "test_normals = X_test_sel[y_test_cancer == 0]\n",
    "\n",
    "if len(test_normals) == 0:\n",
    "    print(\"WARNING: No normal samples in test set — using train normals\")\n",
    "    test_normals = X_train_sel[y_train_cancer == 0]\n",
    "\n",
    "# Tumor fractions to test (log-spaced from 100% down to 0.1%)\n",
    "tumor_fractions = [1.0, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.001]\n",
    "\n",
    "# For each tumor fraction, create synthetic mixtures and test detection\n",
    "results = []\n",
    "\n",
    "# Pick a random normal sample to use as the \"blood background\"\n",
    "np.random.seed(42)\n",
    "bg_normal = test_normals.iloc[np.random.randint(len(test_normals))]\n",
    "\n",
    "print(\"Creating synthetic plasma mixtures...\\n\")\n",
    "for tf in tumor_fractions:\n",
    "    scores = []\n",
    "    for i in range(len(test_tumors)):\n",
    "        tumor = test_tumors.iloc[i]\n",
    "        synthetic = create_synthetic_plasma(tumor, bg_normal, tf)\n",
    "        \n",
    "        # Get cancer probability from our trained classifier\n",
    "        prob = lr_pipeline.predict_proba(synthetic.values.reshape(1, -1))[0, 1]\n",
    "        scores.append(prob)\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    # At what threshold would we call \"cancer detected\"?\n",
    "    # Use the threshold that gives 99.5% specificity on our test set\n",
    "    _, _, threshold_995 = sensitivity_at_specificity(y_test_cancer, lr_probs, 0.995)\n",
    "    detection_rate = (scores >= threshold_995).mean()\n",
    "    \n",
    "    results.append({\n",
    "        'tumor_fraction': tf,\n",
    "        'mean_score': scores.mean(),\n",
    "        'detection_rate': detection_rate,\n",
    "        'n_samples': len(scores)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Tumor fraction {tf:>6.1%}: detection rate = {detection_rate:.1%}, \"\n",
    "          f\"mean score = {scores.mean():.3f}\")\n",
    "\n",
    "dilution_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Plot detection rate vs tumor fraction (LOD curve)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Detection rate\n",
    "ax1.plot(\n",
    "    dilution_results['tumor_fraction'] * 100,\n",
    "    dilution_results['detection_rate'] * 100,\n",
    "    'o-', linewidth=2, markersize=8, color='firebrick'\n",
    ")\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Tumor Fraction (%)')\n",
    "ax1.set_ylabel('Detection Rate (%)')\n",
    "ax1.set_title('Cancer Detection Rate vs Tumor Fraction\\n(at 99.5% specificity threshold)')\n",
    "ax1.axhline(y=50, color='gray', linestyle='--', alpha=0.5, label='50% detection')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Mean classifier score\n",
    "ax2.plot(\n",
    "    dilution_results['tumor_fraction'] * 100,\n",
    "    dilution_results['mean_score'],\n",
    "    's-', linewidth=2, markersize=8, color='steelblue'\n",
    ")\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Tumor Fraction (%)')\n",
    "ax2.set_ylabel('Mean Classifier Score')\n",
    "ax2.set_title('Mean Cancer Probability Score vs Tumor Fraction')\n",
    "ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Decision boundary')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estimate LOD (tumor fraction at 50% detection)\n",
    "above_50 = dilution_results[dilution_results['detection_rate'] >= 0.5]\n",
    "if len(above_50) > 0 and len(above_50) < len(dilution_results):\n",
    "    approx_lod = above_50['tumor_fraction'].min()\n",
    "    print(f\"\\nApproximate LOD (50% detection): ~{approx_lod:.1%} tumor fraction\")\n",
    "    print(f\"(GRAIL reports LOD of 0.07-0.17% for most tumor types)\")\n",
    "else:\n",
    "    print(\"\\nCould not estimate LOD from this data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Next Steps\n",
    "\n",
    "This starter notebook covers the basic pipeline. Here are extensions that\n",
    "would make this a stronger portfolio project and better interview prep:\n",
    "\n",
    "### Preprocessing improvements\n",
    "- Download the 450K manifest and filter sex chromosome + SNP-overlapping probes\n",
    "- Add more cancer types (TCGA has ~33 projects)\n",
    "- Increase sample counts per cancer type\n",
    "\n",
    "### Feature engineering\n",
    "- Instead of individual CpG probes, aggregate into regions (CpG islands, shores, shelves)\n",
    "- Compute variance-based features (methylation heterogeneity within a region)\n",
    "- Try PCA or UMAP for dimensionality reduction and visualization\n",
    "\n",
    "### Modeling\n",
    "- Compare more model types: Random Forest, SVM, elastic net\n",
    "- Nested cross-validation for unbiased performance estimation\n",
    "- Calibration curves — are the predicted probabilities well-calibrated?\n",
    "- Learning curves — how does performance scale with training data?\n",
    "\n",
    "### Dilution experiment\n",
    "- Use multiple different normal backgrounds (not just one)\n",
    "- Add noise to simulate sequencing variability\n",
    "- Test LOD separately per cancer type\n",
    "- Plot sensitivity vs tumor fraction per cancer type (like GRAIL does)\n",
    "\n",
    "### Clinical framing\n",
    "- Calculate PPV and NPV at realistic cancer prevalence (0.5-1%)\n",
    "- Model the impact of different specificity thresholds on screening outcomes\n",
    "- Compare your panel size (non-zero coefficients) to GRAIL's ~100K regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Summary statistics for quick reference\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset: {X.shape[0]} samples, {X.shape[1]} CpG probes\")\n",
    "print(f\"Cancer types: {', '.join(PROJECTS)}\")\n",
    "print(f\"Features selected: {len(selected_probes)}\")\n",
    "print(f\"Features used by L1 model: {n_nonzero}\")\n",
    "print(f\"\\nCancer Detection (L1 LogReg):\")\n",
    "print(f\"  AUC: {auc_lr:.3f}\")\n",
    "for target_spec in [0.99, 0.995]:\n",
    "    sens, _, _ = sensitivity_at_specificity(y_test_cancer, lr_probs, target_spec)\n",
    "    print(f\"  Sensitivity at {target_spec*100:.1f}% specificity: {sens:.3f}\")\n",
    "print(f\"\\nTissue-of-Origin Accuracy: {tof_accuracy:.1%}\")\n",
    "print(f\"\\nDilution results:\")\n",
    "for _, row in dilution_results.iterrows():\n",
    "    print(f\"  {row['tumor_fraction']:>6.1%} tumor fraction → {row['detection_rate']:.0%} detection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
